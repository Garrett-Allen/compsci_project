---
title: "Compsci 390 Final Project"
format: html
editor: visual
---

```{r load packages}
library(tidyverse)
library(yardstick)
library(ngram)
library(randomForest)
library(kgrams)
library(stringr)
library(udpipe)
library(lattice)
library(tidytext)
library(qdap)
library(syuzhet)
library(quanteda)

m_eng_ewt <- udpipe_download_model(language = "english-ewt")
m_eng_ewt_path <- m_eng_ewt$file_model
m_eng_ewt_loaded <- udpipe_load_model(file = m_eng_ewt_path)


```

```{r load and clean data}
review_data <- read.csv("RAW_interactions.csv") %>% 
  mutate(user_id = as.factor(user_id),
         recipe_id = as.factor(recipe_id),
         rating = as.factor(rating),
         date = as.Date(date))

recipes_with_four_reviews <- review_data %>% 
  group_by(recipe_id) %>% 
  count() %>% 
  filter(n >= 4) %>% 
  pull(recipe_id)

review_data <- review_data %>% 
  filter(recipe_id %in% recipes_with_four_reviews) %>% 
  mutate(review = str_replace_all(review,"&#039;","'"),
         review = str_squish(review),
         num_words_review = str_count(review, pattern = " ") + 1)
```

```{r EDA}
review_data %>% 
  ggplot(aes(x = rating)) + 
  geom_bar() + 
  theme_bw() + 
  labs(x = "Rating",
       y = "Frequency",
       title = "Rating data is heavily skewed right")

```

```{r baseline model}
# predict the most common one (5)

review_data %>% 
  count(rating) %>% 
  mutate(perc = n / sum(n))

accuracy_rmse_baseline <- review_data %>% 
  mutate(baseline_model = 5) %>%
  mutate(rating = as.numeric(rating) - 1) %>% 
  summarize(
    accuracy = mean(rating == baseline_model),
    rmse = rmse_vec(rating, baseline_model)
  )

accuracy_rmse_baseline
```

```{r creating linguistically motivated features}
sample <- review_data %>% 
  slice(1) %>% 
  pull(review)

x <- udpipe_annotate(m_eng_ewt_loaded,x = sample) %>% 
    as.data.frame() %>% 
    separate_wider_delim(feats, names_sep = "_", delim = "|", too_few = "align_start") %>% 
    group_by(sentence_id) %>% 
    count(feats_4) %>% 


  
value <- count_table %>% 
    replace(is.na(.),0) %>% 
    ungroup() %>% 
    mutate(tot_words = rowSums(.) - sentence_id) %>% 
    mutate(perc_prs = `PronType=Prs`/tot_words) %>% 
    summarize(percent_pronoun = mean(perc_prs)) %>% 
    pull()

calc_percent_personal_pronoun <- function(sample){
  
  x <- udpipe_annotate(m_eng_ewt_loaded,x = sample) %>% 
    as.data.frame() %>% 
    separate_wider_delim(feats, names_sep = "_", delim = "|", too_few = "align_start")
  
  if(!("feats_4" %in% colnames(x))){
    return(0)
  }
  
  value <- x %>% 
    group_by(sentence_id, feats_4) %>% 
    count() %>% 
    mutate(num_prontype = if_else(!is.na(feats_4) & feats_4 == "PronType=Prs", n, 0),
           prontype_perc = num_prontype / sum(n)) %>% 
    filter(is.na(feats_4) | feats_4 == "PronType=Prs") %>% 
    slice(1) %>% 
    ungroup() %>% 
    summarize(percent_pronoun = mean(prontype_perc)) %>% 
    pull(percent_pronoun)
  
  value
}

##adding sentiments, personal pronouns
review_data_10000 <- review_data %>% 
  sample_n(10000) %>% 
  rowwise() %>% 
  mutate(sentiment = get_nrc_sentiment(review),
         percent_pronoun = calc_percent_personal_pronoun(review),
         type_token = type_token_ratio(review)$all,
         mean_words_sent = mean(str_count(sent_detect_nlp(review), pattern = " ") + 1),
         num_cap_letters_sent = mean(str_count(sent_detect_nlp(review), pattern = "[A-Z]")),
         num_punc_sent = mean(str_count(sent_detect_nlp(review),pattern = "[[:punct:]]"))
         ) %>% 
  unnest()
```

```{r ngrams}


review_data_1000 %>% 
  rowwise() %>% 
  mutate(num_punc_sent = mean(str_count(sent_detect_nlp(review),pattern = "[[:punct:]]")))

```
