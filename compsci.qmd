---
title: "Compsci 390 Final Project"
format: html
editor: visual
---

```{r load packages}
library(tidyverse)
library(yardstick)
library(ngram)
library(randomForest)
library(kgrams)
library(stringr)
library(udpipe)
library(lattice)
library(tidytext)
library(qdap)
library(syuzhet)
library(quanteda)
library(reticulate)
library(e1071)
library(glmnet)

m_eng_ewt <- udpipe_download_model(language = "english-ewt")
m_eng_ewt_path <- m_eng_ewt$file_model
m_eng_ewt_loaded <- udpipe_load_model(file = m_eng_ewt_path)


```

```{r load and clean data}
review_data <- read.csv("RAW_interactions.csv") %>% 
  mutate(user_id = as.factor(user_id),
         recipe_id = as.factor(recipe_id),
         rating = as.factor(rating),
         date = as.Date(date)
  )

recipes_with_four_reviews <- review_data %>% 
  group_by(recipe_id) %>% 
  count() %>% 
  filter(n >= 4) %>% 
  pull(recipe_id)

review_data <- review_data %>% 
  filter(recipe_id %in% recipes_with_four_reviews) %>% 
  mutate(review = str_replace_all(review,"&#039;","'"),
         review = str_squish(review),
         num_words_review = str_count(review, pattern = " ") + 1,
         id  = 1:n())
```

```{r EDA}
review_data %>% 
  ggplot(aes(x = rating)) + 
  geom_bar() + 
  theme_bw() + 
  labs(x = "Rating",
       y = "Frequency",
       title = "Rating data is heavily skewed right")

```

```{r baseline model}
# predict the most common one (5)

review_data %>% 
  count(rating) %>% 
  mutate(perc = n / sum(n))

accuracy_rmse_baseline <- review_data %>% 
  mutate(baseline_model = 5) %>%
  mutate(rating = as.numeric(rating) - 1) %>% 
  summarize(
    accuracy = mean(rating == baseline_model),
    rmse = rmse_vec(rating, baseline_model)
  )

accuracy_rmse_baseline
```

```{r creating linguistically motivated features}
set.seed(123)

calc_percent_personal_pronoun <- function(sample){
  
  x <- udpipe_annotate(m_eng_ewt_loaded,x = sample) %>% 
    as.data.frame() %>% 
    separate_wider_delim(feats, names_sep = "_", delim = "|", too_few = "align_start")
  
  if(!("feats_4" %in% colnames(x))){
    return(0)
  }
  
  value <- x %>% 
    group_by(sentence_id, feats_4) %>% 
    count() %>% 
    mutate(num_prontype = if_else(!is.na(feats_4) & feats_4 == "PronType=Prs", n, 0),
           prontype_perc = num_prontype / sum(n)) %>% 
    filter(is.na(feats_4) | feats_4 == "PronType=Prs") %>% 
    slice(1) %>% 
    ungroup() %>% 
    summarize(percent_pronoun = mean(prontype_perc)) %>% 
    pull(percent_pronoun)
  
  value
}

##adding sentiments, personal pronouns
review_data_1000 <- review_data %>% 
  sample_n(10000) %>% 
  rowwise() %>% 
  mutate(sentiment = get_nrc_sentiment(review),
         percent_pronoun = calc_percent_personal_pronoun(review),
         type_token = type_token_ratio(review)$all,
         mean_words_sent = mean(str_count(sent_detect_nlp(review), pattern = " ") + 1),
         num_cap_letters_sent = mean(str_count(sent_detect_nlp(review), pattern = "[A-Z]")),
         num_punc_sent = mean(str_count(sent_detect_nlp(review),pattern = "[[:punct:]]"))
         ) %>% 
  unnest()
  
```

```{python passive sentences}
import pandas
from PassivePySrc import PassivePy

passivepy = PassivePy.PassivePyAnalyzer(spacy_model = "en_core_web_lg")

reviews = r.review_data_1000

df_detected_s = passivepy.match_sentence_level(reviews, column_name= 'review',
                                                batch_size = 1000, add_other_columns=True,
                                                truncated_passive=False, full_passive=False)
                                              
```

```{r full dataset}
review_data_1000 <- py$df_detected_s %>% 
  group_by(docId) %>% 
  mutate(mean_passive = mean(unlist(binary))) %>% 
  select(user_id,recipe_id,mean_passive) %>% 
  ungroup(docId) %>% 
  left_join(review_data_1000) %>% 
  select(-docId) %>% 
  distinct()
  
```


```{r train test split}
n <- nrow(review_data_1000)

review_data_1000 <- review_data_1000 %>% 
  mutate(across(.cols = 8:17, as.factor)) %>% 
  select(-date, -review, -user_id, -recipe_id)

train <- review_data_1000 %>% 
  sample_n(.8 * n)

validate <- anti_join(review_data_1000,train) %>% 
  sample_n(.1 * n)

test <- anti_join(anti_join(review_data_1000,train),validate)
```
```{r modeling}
#lasso
kmer3model <- cv.glmnet(kmer3_x_training, family_training, family = "multinomial", nfolds = 5, type.measure = "class", trace.it = 1, parallel = TRUE)

#random forest

rf_model <- randomForest(rating ~ ., data = select(train,-id), ntree = 1000)

#SVM
```
